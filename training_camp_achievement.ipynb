{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family_group</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  Family_group  Family  \n",
       "0      0         A/5 21171   7.2500   NaN        S             1       2  \n",
       "1      0          PC 17599  71.2833   C85        C             1       2  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S             0       1  \n",
       "3      0            113803  53.1000  C123        S             1       2  \n",
       "4      0            373450   8.0500   NaN        S             0       1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression  # as LR\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "#%matplotlib inline\n",
    "\n",
    "#データの取得\n",
    "train = pd.read_csv(\"/Users/happycatcat523/pyworks/kaggle資料/titanic/train.csv\")\n",
    "test = pd.read_csv(\"/Users/happycatcat523/pyworks/kaggle資料/titanic/test.csv\")\n",
    "\n",
    "#単身旅行者と団体旅行者の特徴量を新しく作成\n",
    "train['Family_group'] = train.SibSp + train.Parch\n",
    "test['Family_group'] = test.SibSp + test.Parch\n",
    "\n",
    "#家族人数の特徴量を新しく作成\n",
    "train['Family'] = train.SibSp + train.Parch + 1\n",
    "test['Family'] = test.SibSp + test.Parch + 1\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.368090452261306\n",
      "21.773972602739725\n",
      "35.898148148148145\n",
      "4.574166666666667\n",
      "29.69911764705882 \n",
      "\n",
      "32.0\n",
      "21.774843750000002\n",
      "38.903225806451616\n",
      "7.406470588235294\n",
      "30.272590361445783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/happycatcat523/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/happycatcat523/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/happycatcat523/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/happycatcat523/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/happycatcat523/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/happycatcat523/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/happycatcat523/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/happycatcat523/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Family_groupの特徴量をダミー変数に変換\n",
    "train['Family_group'] = train['Family_group'].where(train['Family_group'] == 0, 0)\n",
    "train['Family_group'] = train['Family_group'].fillna(1)\n",
    "test['Family_group'] = test['Family_group'].where(test['Family_group'] == 0, 0)\n",
    "test['Family_group'] = test['Family_group'].fillna(1)\n",
    "\n",
    "#敬称ごとにindexの格納\n",
    "train_mr_index = train['Name'].str.contains(' Mr. ')\n",
    "train_miss_index = train['Name'].str.contains(' Miss. ')\n",
    "train_mrs_index = train['Name'].str.contains(' Mrs. ')\n",
    "train_master_index = train['Name'].str.contains(' Master. ')\n",
    "test_mr_index = test['Name'].str.contains(' Mr. ')\n",
    "test_miss_index = test['Name'].str.contains(' Miss. ')\n",
    "test_mrs_index = test['Name'].str.contains(' Mrs. ')\n",
    "test_master_index = test['Name'].str.contains(' Master. ')\n",
    "\n",
    "#敬称ごとの平均値の算出\n",
    "train_mr = train[train['Name'].str.contains(' Mr. ')]\n",
    "train_miss = train[train['Name'].str.contains(' Miss. ')]\n",
    "train_mrs = train[train['Name'].str.contains(' Mrs. ')]\n",
    "train_master = train[train['Name'].str.contains(' Master. ')]\n",
    "test_mr = test[test['Name'].str.contains(' Mr. ')]\n",
    "test_miss = test[test['Name'].str.contains(' Miss. ')]\n",
    "test_mrs = test[test['Name'].str.contains(' Mrs. ')]\n",
    "test_master = test[test['Name'].str.contains(' Master. ')]\n",
    "\n",
    "train_mr_num = train_mr['Age'].dropna().mean()\n",
    "train_miss_num = train_miss['Age'].dropna().mean()\n",
    "train_mrs_num = train_mrs['Age'].dropna().mean()\n",
    "train_master_num = train_master['Age'].dropna().mean()\n",
    "train_all_num = train['Age'].dropna().mean()\n",
    "print(train_mr_num)\n",
    "print(train_miss_num)\n",
    "print(train_mrs_num)\n",
    "print(train_master_num)\n",
    "print(train_all_num, '\\n')\n",
    "test_mr_num = test_mr['Age'].dropna().mean()\n",
    "test_miss_num = test_miss['Age'].dropna().mean()\n",
    "test_mrs_num = test_mrs['Age'].dropna().mean()\n",
    "test_master_num = test_master['Age'].dropna().mean()\n",
    "test_all_num = test['Age'].dropna().mean()\n",
    "print(test_mr_num)\n",
    "print(test_miss_num)\n",
    "print(test_mrs_num)\n",
    "print(test_master_num)\n",
    "print(test_all_num)\n",
    "\n",
    "#欠損値”Age”に対しての敬称ごとの平均値の補完\n",
    "train['Age'][train_mr_index] = train_mr['Age'].fillna(32)\n",
    "train['Age'][train_miss_index] = train_master['Age'].fillna(22)\n",
    "train['Age'][train_mrs_index] = train_mrs['Age'].fillna(36)\n",
    "train['Age'][train_master_index] = train_master['Age'].fillna(5)\n",
    "train['Age'] = train['Age'].fillna(30)\n",
    "\n",
    "test['Age'][test_mr_index] = test_mr['Age'].fillna(32)\n",
    "test['Age'][test_miss_index] = test_miss['Age'].fillna(22)\n",
    "test['Age'][test_mrs_index] = test_mrs['Age'].fillna(36)\n",
    "test['Age'][test_master_index] = test_master['Age'].fillna(5)\n",
    "test['Age'] = test['Age'].fillna(30)\n",
    "\n",
    "#その他欠損値の補完\n",
    "train['Embarked'] = train['Embarked'].fillna('S')\n",
    "test['Fare'] = test['Fare'].fillna(test['Fare'].mean())\n",
    "\n",
    "#性別と乗船港をダミー変数への変換\n",
    "dummy_train = pd.get_dummies(train[['Sex', 'Embarked']])\n",
    "dummy_test = pd.get_dummies(test[['Sex', 'Embarked']])\n",
    "\n",
    "train_two = pd.concat([train.drop([\"Sex\", \"Embarked\"], axis = 1),dummy_train], axis = 1)\n",
    "test_two = pd.concat([test.drop([\"Sex\", \"Embarked\"], axis = 1),dummy_test], axis = 1)\n",
    "\n",
    "#不要な特徴量の削除\n",
    "train_three = train_two.drop(['PassengerId', 'Name', 'SibSp', 'Ticket', 'Cabin', 'Parch'], axis = 1)\n",
    "x_test = test_two.drop(['PassengerId', 'Name', 'SibSp', 'Ticket', 'Cabin', 'Parch'], axis = 1)\n",
    "\n",
    "#データフレーム型への変換\n",
    "x_train_df = train_three.drop(['Survived'], axis = 1)\n",
    "x_train = x_train_df\n",
    "\n",
    "#目的変数の格納\n",
    "y_train = train_three.Survived\n",
    "\n",
    "#決定木の学習を行う\n",
    "depth = 4\n",
    "clf = tree.DecisionTreeClassifier(max_depth = depth)\n",
    "clf.fit(x_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf no: 4\n",
      "leaf no: 5\n",
      "leaf no: 7\n",
      "leaf no: 8\n",
      "leaf no: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/happycatcat523/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:553: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf no: 12\n",
      "leaf no: 14\n",
      "leaf no: 15\n",
      "leaf no: 19\n",
      "leaf no: 20\n",
      "leaf no: 22\n",
      "leaf no: 23\n",
      "leaf no: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/happycatcat523/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:553: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n",
      "/Users/happycatcat523/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:553: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf no: 27\n",
      "leaf no: 29\n",
      "leaf no: 30\n"
     ]
    }
   ],
   "source": [
    "#applyクラスでリーフごとのリーフ番号を返す\n",
    "x_train_leaf_no = clf.apply(x_train_df)\n",
    "x_test_leaf_no = clf.apply(x_test)\n",
    "\n",
    "\n",
    "#リーフごとにロジスティック回帰分析を行う\n",
    "\n",
    "#全てのindexを０にした配列を用意しておく\n",
    "x_train_proba = np.zeros(x_train.shape[0])\n",
    "x_test_proba = np.zeros(x_test.shape[0])\n",
    "\n",
    "#重複しないリーフ番号をリストに格納する\n",
    "unique_leaf_no = list(set(x_train_leaf_no))\n",
    "\n",
    "#ロジスティック回帰のハイパーパラメータのチューニング\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "#格納したリーフ番号を取り出す\n",
    "for i in unique_leaf_no :\n",
    "    #取り出すリーフ番号の確認\n",
    "    print('leaf no:', i)\n",
    "    \n",
    "    #trainデータのリーフ番号を指定して取り出したデータフレームを変数に格納\n",
    "    leaf_data_train_x = x_train[x_train_leaf_no == i]\n",
    "    leaf_data_train_y = y_train[x_train_leaf_no == i]\n",
    "    #testデータのリーフ番号を指定して取り出したデータフレームを変数に格納\n",
    "    leaf_data_test_x = x_test[x_test_leaf_no == i]\n",
    "    \n",
    "\n",
    "    #一度、ダミー変数のデータを除外する\n",
    "    leaf_data_train_x_drop = leaf_data_train_x.drop(['Family_group', 'Family', 'Pclass', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_S', 'Embarked_Q'], axis = 1)\n",
    "    leaf_data_test_x = leaf_data_test_x.drop(['Family_group', 'Family', 'Pclass', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_S', 'Embarked_Q'], axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    #survivedの値に生存者と死亡者の両方がいる場合\n",
    "    if len(set(leaf_data_train_y)) > 1:\n",
    "        \n",
    "        #GridSearchを行う\n",
    "        try:\n",
    "            grid_search = GridSearchCV(LogisticRegression(), param_grid, cv = 5, scoring = 'roc_auc')   \n",
    "            grid_search.fit(leaf_data_train_x_drop, leaf_data_train_y)\n",
    "            clf = LogisticRegression(C=grid_search.best_params_['C'],class_weight=\"balanced\")\n",
    "        except (ValueError, TypeError, NameError, SyntaxError):\n",
    "            clf = LogisticRegression()\n",
    "        \n",
    "        #ロジスティック回帰分析を行う\n",
    "        clf.fit(leaf_data_train_x_drop, leaf_data_train_y)\n",
    "        \n",
    "        #所属しているクラスの確率を戻す\n",
    "        a = clf.predict_proba(leaf_data_train_x_drop)\n",
    "        \n",
    "        #生存の場合の確率のみを格納\n",
    "        x_train_proba[x_train_leaf_no == i] = a[:,1]\n",
    "       \n",
    "        if len(leaf_data_test_x) > 0:\n",
    "            b = clf.predict_proba(leaf_data_test_x)    \n",
    "            x_test_proba[x_test_leaf_no == i] = b[:,1]\n",
    "        \n",
    "        \n",
    "    #survivedの値に生存者と死亡者のどちらかしかいない場合    \n",
    "    else:\n",
    "        x_train_proba[x_train_leaf_no == i] = leaf_data_train_y.head(1)\n",
    "        if len(leaf_data_test_x) > 0:\n",
    "            x_test_proba[x_test_leaf_no == i] =leaf_data_train_y.head(1)\n",
    "        \n",
    "        \n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for loop end\n"
     ]
    }
   ],
   "source": [
    "#ループ終了の確認\n",
    "print(\"for loop end\")\n",
    "\n",
    "#生存と死亡の確率のデータフレームを結合\n",
    "train_data = pd.concat([x_train, pd.DataFrame(x_train_proba)], axis =1)\n",
    "test_data = pd.concat([x_test, pd.DataFrame(x_test_proba)], axis =1)\n",
    "\n",
    "#ロジスティック回帰のハイパーパラメータのチューニング\n",
    "param_grid = {'max_depth': [3,5,8,13,15]}\n",
    "\n",
    "#GridSearchを行う\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(n_estimators=100), param_grid, cv = 5, scoring = 'roc_auc')   \n",
    "grid_search.fit(train_data, y_train)\n",
    "\n",
    "#勾配ブースティングによる学習と予測\n",
    "model = GradientBoostingClassifier(max_depth=grid_search.best_params_['max_depth'], n_estimators=100)\n",
    "model.fit(train_data, y_train)\n",
    "output = model.predict(test_data).astype(int)\n",
    "\n",
    "\n",
    "#結果をCSVに変換\n",
    "leaf_data_test = pd.DataFrame({\n",
    "    \"PassengerId\": test[\"PassengerId\"],\n",
    "    \"Survived\": output\n",
    "})\n",
    "leaf_data_test.to_csv('training_camp05.csv', index = False)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
